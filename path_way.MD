
## Module 2: Classification

- [X] [Naive Bayes classification](https://izhangzhihao.github.io/2017/11/16/朴素贝叶斯分类/)
- [X] K-NN classification (Skipped)
- [X] [Linear Discriminant Analysis](https://izhangzhihao.github.io/2017/11/17/主成分分析(PCA)和线性判别分析(LDA)/)

## Module 3: Regression

- [X] [Linear Regression](https://github.com/izhangzhihao/MachineLearningInAction/blob/master/linear_regression.py)
- [X] [Logistic Regression](https://github.com/izhangzhihao/MachineLearningInAction/blob/master/logistic_regression.py)
- [X] [Nonlinear Regression / Polynomial Regression](https://github.com/izhangzhihao/MachineLearningInAction/blob/master/convolutional_network.py)

## Module 4: Unsupervised learning

- [X] [Principal Component Analysis](https://izhangzhihao.github.io/2017/11/17/主成分分析(PCA)和线性判别分析(LDA)/)
- [X] [Euclidean distance, edit distance, jaccard distance](https://izhangzhihao.github.io/2017/11/18/范数和距离/)
- [X] [Cosine similarity](https://izhangzhihao.github.io/2017/11/18/范数和距离/)
- [X] [Clustering](https://izhangzhihao.github.io/2017/11/19/聚类/)
    - [X] K-means clustering
    - [X] Hierarchical clustering
    - [X] Spectral clustering
    - [X] GMM clustering

## Module 5: Machine Learning Model Development (intermediate - advanced)

- [ ] Evaluating machine learning models
    - [X] [Curse of dimensionality / Occam’s razor](https://izhangzhihao.github.io/2017/11/21/维数灾难和奥卡姆剃刀/)
        - [X] Vapnik-Chernovenkis (VC) dimension
    - [X] [Underfitting and overfitting](https://izhangzhihao.github.io/2017/11/22/欠拟合和过拟合/)
    - [X] [Hypothesis testing and Statistical significance](https://izhangzhihao.github.io/2017/11/23/假设检验和显著性差异/)
    - [X] Cross validation(Skipped)
        - [ ] Leave one-out
        - [ ] K-fold validation
- [X] [Training error and loss functions](https://izhangzhihao.github.io/2017/11/25/Ativation-functions-and-loss-functions/)
    - [X] Absolute loss
    - [X] Squared loss
    - [X] Zero/one loss
    - [X] Cross entropy loss
- [ ] Advanced Feature Engineering
- [ ] Algorithm Selection

## Module 6: Decision Trees

- [ ] Features
- [ ] Loss function

## Module 7: Ensemble Learning

- [ ] Bagging
- [ ] Boosting
- [ ] Random forest

## Module 8: Support Vector Machines

- [ ] Linear SVM
- [ ] ELM - Extreme Learning Machine

## Module 9: Perceptrons

- [ ] Perceptrons
- [ ] Multi-layer perceptrons
- [ ] Momentum

## Module 10: Neural Networks

- [ ] Back-propagation networks
- [ ] Multi-layer networks
- [ ] Hopfield networks
- [ ] Softmax networks

## Module 11: Expectation-Maximisation

- [ ] Expectation-maximisation (EM) algorithms

## Module 12: Graphical Models

- [ ] Bayesian networks
- [ ] Markov models
- [ ] Markov random fields
- [ ] Hidden Markov models
- [ ] Conditional random field